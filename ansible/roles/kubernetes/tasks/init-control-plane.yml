# TODO: set node_labels


- name: Kubernetes etc directory
  become: true
  ansible.builtin.file:
    path: /etc/kubernetes/
    state: directory
    mode: '0775'


- name: Copy Kubeadm config
  become: true
  template:
    src: kubeadm-config.yaml.j2
    dest: /etc/kubernetes/kubeadm-config.yaml
    owner: root
    group: root
    mode: 0644


- name: Kubeadm init
  become: true
  register: ret
  failed_when: (ret.rc != 0)
  ansible.builtin.shell: |
    set -eu
    #    kubeadm reset --force

    if [ ! -d /var/lib/etcd/member ]; then
      kubeadm config images pull

      kubeadm init --skip-phases=addon/kube-proxy \
          --config /etc/kubernetes/kubeadm-config.yaml
    else
      # Run a kubectl command, it should work since we ran kubeadm before
      sudo -u vagrant kubectl get nodes
    fi

- name: Get kubeconfig
  ansible.builtin.shell: |
    set -eu
    mkdir -p "$HOME/.kube"
    sudo cp /etc/kubernetes/admin.conf "$HOME/.kube/config"
    sudo chown -R $(id -u):$(id -g) "$HOME/.kube"

- name: Add Cilium chart repo
  kubernetes.core.helm_repository:
    name: cilium
    repo_url: "https://helm.cilium.io/"



# TODO: Maybe cordon and drain node before updating Cilium?
- name: Install Cilium
  kubernetes.core.helm:
    name: cilium
    chart_ref: cilium/cilium
    release_namespace: kube-system
    chart_version: "{{ cilium_version }}"
    wait: true
    values:
      egressGateway:
        enabled: true
      bpf:
        masquerade: true
      kubeProxyReplacement: true
      k8sServiceHost: "{{ node_ip_address }}"
      k8sServicePort: 6443
#      operator:
#        replicas: 1

